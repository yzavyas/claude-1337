# claude-1337

Cognitive extensions for *effective* collaborative intelligence.

---

## The Problem

Most AI collaboration isn't effective.

| finding | source |
|---------|--------|
| Human-AI combos underperform best alone (g = -0.23) | Vaccaro 2024, 106 studies |
| Developers 19% slower while feeling 20% faster | METR 2025, RCT |
| AI use correlates with lower critical thinking (r = -0.75) | Gerlich 2025 |

These are correlations, not proven mechanisms. But the pattern is consistent: **ineffective AI use degrades capability while creating false confidence.**

## The Solution

Effectiveness requires intentional design. Extensions that:

- Show reasoning (transparency)
- Provide control (agency)
- Build capability (bidirectional learning)

Research: These features showed strong positive effects ([Blaurock 2024](https://journals.sagepub.com/doi/full/10.1177/10946705241238751)).

---

## For Decision-Makers

### The Risk

Your AI investment may be reducing team productivity while creating false confidence. The research shows:

- Developers felt 20% more productive but measured 19% slower (METR 2025)
- Human-AI combinations underperformed solo experts, g = -0.23 (Vaccaro 2024)
- AI use correlated with lower critical thinking scores, r = -0.75 (Gerlich 2025)

These findings suggest a risk of capability degradation that feels like improvement.

### The Opportunity

Collaborative intelligence works differently:

- **Transparent abstractions**: Team sees reasoning, learns patterns, maintains capability
- **Bidirectional learning**: Both human and AI improve through the work
- **Crystallized knowledge**: Breakthroughs persist as extensions

Research: Transparency and control features showed strong positive effects on collaboration outcomes ([Blaurock et al. 2024](https://journals.sagepub.com/doi/full/10.1177/10946705241238751)).

### Next Steps

1. [Review the research](/explore/explanation/ethos) — understand what makes collaboration succeed or fail
2. [See the methodology](/explore/explanation/principles) — evidence-based extension design
3. [Evaluate for your context](/explore/reference/bibliography) — full citations and effect sizes

---

## For Builders

### Get Started

Add the marketplace and install core methodology:

```bash
/plugin marketplace add yzavyas/claude-1337
/plugin install core-1337@claude-1337
```

### Browse Extensions

[Explore the catalog](/explore/reference/catalog) — skills, hooks, agents, commands, MCP servers.

### Build Extensions

Extensions are readable markdown. See how they work, learn from them, fork them:

```
plugins/
├── core-1337/           → Evidence-based methodology
├── sensei-1337/         → Teaching and documentation
├── 1337-extension-builder/ → Build your own
└── [your-extension]/    → Your crystallized breakthroughs
```

[Learn extension building](/explore/how-to/build-extensions)

### The Continuous Improvement Loop

```
collaboration → breakthrough → crystallization → improved baseline
```

When you figure something out together, write it down. The extension persists. Next session starts from that new baseline.

---

## The Framework

This project has both a philosophy and evidence informing it.

- [**Ethos**](/explore/explanation/ethos) — our values and why we hold them
- [**Research**](/explore/reference/research) — empirical findings on human-AI collaboration
- [**Principles**](/explore/explanation/principles) — design guidelines derived from both
- [**Bibliography**](/explore/reference/bibliography) — full citations, methodology, effect sizes
- [**Catalog**](/explore/reference/catalog) — available extensions and their purposes

---

## What Makes This Different

Extensions aren't hidden black boxes. They're **transparent abstractions**:

- **Readable**: Plaintext markdown, no magic
- **Forkable**: Copy, modify, make your own
- **Verifiable**: Claims have sources, methodology visible
- **Observable**: See what Claude does with them

If you can't see how it works, you can't learn from it.
