# ethos

What we're optimizing for and why it matters.

---

## the goal

Extensions that make you **more capable**, not more dependent.

The difference: after using a tool, you're the same. After engaging with a cognitive extension, you understand something you didn't before.

---

## the risk

Human-AI collaboration fails by default. The research is clear:

- **Vaccaro et al. (2024)**: Human-AI teams perform worse than best alone (g = -0.23)
- **Gerlich (2025)**: r = -0.75 correlation between AI use and critical thinking decline
- **METR (2025)**: Developers 19% slower with AI, but perceived themselves 20% faster

The mechanism: offload thinking → consume output → capability atrophies → can't tell it's happening.

---

## the principles

| principle | what it means | why it matters |
|-----------|---------------|----------------|
| **collaborative agency** | both human and AI retain judgment | compliance is brittle; understanding scales |
| **bidirectional learning** | both develop through collaboration | you grow, not just the system |
| **transparent abstractions** | readable, forkable, verifiable | if you can't see it, you can't learn from it |
| **composable architecture** | extensions build on each other | compound improvements, not reinvention |

---

## for builders

Design for enhancement, not replacement:

- Show reasoning, not just conclusions
- Provide decision frameworks, not decisions
- Cite sources so claims can be verified
- Make extensions readable — someone should learn by reading them

---

[full explanation →](/explore/explanation/ethos/)
