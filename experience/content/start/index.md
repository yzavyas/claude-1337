# claude-1337

A marketplace of cognitive extensions for effective human-AI collaboration.

---

## The Bottom Line

Three numbers that matter:

- **g = -0.23**: Human-AI combinations perform worse than the best performer alone ([Vaccaro et al. 2024](https://www.nature.com/articles/s41562-024-02024-1), meta-analysis of 106 studies)
- **19% slower, 20% faster perception**: Developers are actually slower with AI tools while perceiving themselves faster ([METR 2025](https://arxiv.org/abs/2507.09089), randomized controlled trial)
- **r = -0.75**: Strong negative correlation between AI use and critical thinking (Gerlich 2025)

These are correlations, not proven causal mechanisms. But the pattern is consistent across studies.

---

## For Decision-Makers

### The Risk

Your AI investment may be reducing team productivity while creating false confidence. The research shows:

- Developers felt 20% more productive but measured 19% slower (METR 2025)
- Human-AI combinations underperformed solo experts, g = -0.23 (Vaccaro 2024)
- AI use correlated with lower critical thinking scores, r = -0.75 (Gerlich 2025)

These findings suggest a risk of capability degradation that feels like improvement.

### The Opportunity

Collaborative intelligence works differently:

- **Transparent abstractions**: Team sees reasoning, learns patterns, maintains capability
- **Bidirectional learning**: Both human and AI improve through the work
- **Crystallized knowledge**: Breakthroughs persist as extensions

Research: Transparency and control features showed strong positive effects on collaboration outcomes ([Blaurock et al. 2024](https://journals.sagepub.com/doi/full/10.1177/10946705241238751)).

### Next Steps

1. [Review the research](/explore/explanation/ethos) — understand what makes collaboration succeed or fail
2. [See the methodology](/explore/explanation/principles) — evidence-based extension design
3. [Evaluate for your context](/explore/reference/bibliography) — full citations and effect sizes

---

## For Builders

### Get Started

Add the marketplace and install core methodology:

```bash
/plugin marketplace add yzavyas/claude-1337
/plugin install core-1337@claude-1337
```

### Browse Extensions

[Explore the catalog](/explore/reference/catalog) — skills, hooks, agents, commands, MCP servers.

### Build Extensions

Extensions are readable markdown. See how they work, learn from them, fork them:

```
plugins/
├── core-1337/           → Evidence-based methodology
├── sensei-1337/         → Teaching and documentation
├── 1337-extension-builder/ → Build your own
└── [your-extension]/    → Your crystallized breakthroughs
```

[Learn extension building](/explore/how-to/build-extensions)

### The Continuous Improvement Loop

```
collaboration → breakthrough → crystallization → improved baseline
```

When you figure something out together, write it down. The extension persists. Next session starts from that new baseline.

---

## The Framework

This project has both a philosophy and evidence informing it.

- [**Ethos**](/explore/explanation/ethos) — our values and why we hold them
- [**Research**](/explore/reference/research) — empirical findings on human-AI collaboration
- [**Principles**](/explore/explanation/principles) — design guidelines derived from both
- [**Bibliography**](/explore/reference/bibliography) — full citations, methodology, effect sizes
- [**Catalog**](/explore/reference/catalog) — available extensions and their purposes

---

## What Makes This Different

Extensions aren't hidden black boxes. They're **transparent abstractions**:

- **Readable**: Plaintext markdown, no magic
- **Forkable**: Copy, modify, make your own
- **Verifiable**: Claims have sources, methodology visible
- **Observable**: See what Claude does with them

If you can't see how it works, you can't learn from it.
