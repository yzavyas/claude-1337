# claude-1337

A marketplace of cognitive extensions for effective human-AI collaboration.

---

## The Bottom Line

Three numbers that matter:

- **g = -0.23**: Human-AI combinations perform worse than the best performer alone ([Vaccaro et al. 2024](https://www.nature.com/articles/s41562-024-02024-1), meta-analysis of 106 studies)
- **19% slower, 20% faster perception**: Developers are actually slower with AI tools while perceiving themselves faster ([METR 2025](https://arxiv.org/abs/2507.09089), randomized controlled trial)
- **r = -0.75**: Strong negative correlation between AI use and critical thinking (Gerlich 2025)

**The mechanism**: Hidden abstractions → less thinking → skill decay you don't notice.

**The trajectory**: This compounds. Default AI collaboration hollows out capability while boosting confidence.

---

## For Decision-Makers

### The Risk

Your AI investment may be reducing team productivity while creating false confidence. The research shows:

- Developers feel 20% more productive but ship 19% slower
- Human-AI combinations underperform solo experts by effect size g = -0.23
- Skills atrophy measurably (r = -0.75) when AI use replaces thinking

Cost: degraded capability that looks like improvement.

### The Opportunity

Collaborative intelligence works differently:

- **Transparent abstractions**: Team sees reasoning, learns patterns, maintains capability
- **Bidirectional learning**: Both human and AI improve through the work
- **Crystallized knowledge**: Breakthroughs persist as extensions

Evidence: When designed for transparency and control ([Blaurock et al. 2024](https://journals.sagepub.com/doi/full/10.1177/10946705241238751)), AI collaboration enhances rather than hollows.

### Next Steps

1. [Review the research](/explore/explanation/ethos) — understand what makes collaboration succeed or fail
2. [See the methodology](/explore/explanation/principles) — evidence-based extension design
3. [Evaluate for your context](/explore/reference/bibliography) — full citations and effect sizes

---

## For Builders

### Get Started

Add the marketplace and install core methodology:

```bash
/plugin marketplace add yzavyas/claude-1337
/plugin install core-1337@claude-1337
```

### Browse Extensions

[Explore the catalog](/explore/reference/catalog) — skills, hooks, agents, commands, MCP servers.

### Build Extensions

Extensions are readable markdown. See how they work, learn from them, fork them:

```
plugins/
├── core-1337/           → Evidence-based methodology
├── sensei-1337/         → Teaching and documentation
├── 1337-extension-builder/ → Build your own
└── [your-extension]/    → Your crystallized breakthroughs
```

[Learn extension building](/explore/how-to/build-extensions)

### The Continuous Improvement Loop

```
collaboration → breakthrough → crystallization → improved baseline
```

When you figure something out together, write it down. The extension persists. Next session starts from that new baseline.

---

## The Research

This isn't philosophy — it's evidence-based collaborative intelligence.

- [**Ethos**](/explore/explanation/ethos) — why this matters, what the research shows
- [**Principles**](/explore/explanation/principles) — design for transparency and learning
- [**Bibliography**](/explore/reference/bibliography) — full citations, methodology, effect sizes
- [**Catalog**](/explore/reference/catalog) — available extensions and their purposes

---

## What Makes This Different

Extensions aren't hidden black boxes. They're **transparent abstractions**:

- **Readable**: Plaintext markdown, no magic
- **Forkable**: Copy, modify, make your own
- **Verifiable**: Claims have sources, methodology visible
- **Observable**: See what Claude does with them

If you can't see how it works, you can't learn from it. If you can't learn from it, it hollows rather than enhances.
