"""Markdown report generator for activation test results."""

from .models import ActivationReport, RunStatus


def generate_markdown_report(report: ActivationReport) -> str:
    """Generate a GitHub-friendly markdown report.

    Args:
        report: The activation test report

    Returns:
        Markdown string suitable for PRs/issues
    """
    lines = [
        f"# Skill Activation Report: {report.suite_name}",
        "",
        f"**Date**: {report.timestamp.strftime('%Y-%m-%d %H:%M:%S')}",
        f"**Total Runs**: {report.total_runs}",
        f"**Overall Activation Rate**: {report.activation_rate * 100:.1f}%",
        "",
        "## Summary",
        "",
        "| Skill | Activated | Total | Rate |",
        "|-------|-----------|-------|------|",
    ]

    stats = report.skill_stats()
    for skill_name, data in sorted(stats.items()):
        rate = data["rate"] * 100
        emoji = "+" if rate >= 80 else "~" if rate >= 50 else "-"
        lines.append(
            f"| {skill_name} | {data['activated']} | {data['total']} | {emoji}{rate:.0f}% |"
        )

    lines.extend(
        [
            "",
            "## Detailed Results",
            "",
        ]
    )

    current_skill = None
    for run in report.runs:
        if run.skill_name != current_skill:
            current_skill = run.skill_name
            lines.extend(
                [
                    f"### {current_skill}",
                    "",
                ]
            )

        status_emoji = {
            RunStatus.ACTIVATED: "+",
            RunStatus.NOT_ACTIVATED: "-",
            RunStatus.ERROR: "!",
        }.get(run.status, "?")

        prompt_preview = run.prompt[:60] + "..." if len(run.prompt) > 60 else run.prompt
        lines.append(f"- [{status_emoji}] `{prompt_preview}`")

        if run.tool_calls:
            tools = ", ".join(run.tool_calls[:5])
            lines.append(f"  - Tools: {tools}")

        if run.error:
            lines.append(f"  - Error: {run.error[:100]}")

    lines.extend(
        [
            "",
            "---",
            "",
            "## Methodology",
            "",
            "Tests run using Claude Agent SDK. Activation is measured by detecting",
            "`Skill()` tool calls in the response stream - this is ground truth,",
            "not asking Claude if it would use a skill.",
            "",
            "**Legend**:",
            "- `+` = Skill activated (Skill() tool called)",
            "- `-` = Skill not activated",
            "- `!` = Error during test",
            "",
            "*Generated by claude-1337-evals*",
        ]
    )

    return "\n".join(lines)


def generate_comparison_report(
    baseline: ActivationReport,
    hooks: ActivationReport,
) -> str:
    """Generate a comparison report between baseline and hooks-enabled runs.

    Args:
        baseline: Results without forced hooks
        hooks: Results with forced hooks

    Returns:
        Markdown comparison report
    """
    lines = [
        "# Skill Activation Comparison Report",
        "",
        f"**Date**: {baseline.timestamp.strftime('%Y-%m-%d %H:%M:%S')}",
        "",
        "## Overall Comparison",
        "",
        "| Metric | Baseline | With Hooks | Improvement |",
        "|--------|----------|------------|-------------|",
    ]

    baseline_rate = baseline.activation_rate * 100
    hooks_rate = hooks.activation_rate * 100
    improvement = hooks_rate - baseline_rate

    lines.append(
        f"| Activation Rate | {baseline_rate:.1f}% | {hooks_rate:.1f}% | +{improvement:.1f}% |"
    )
    lines.append(f"| Total Runs | {baseline.total_runs} | {hooks.total_runs} | - |")

    lines.extend(
        [
            "",
            "## Per-Skill Comparison",
            "",
            "| Skill | Baseline | With Hooks | Delta |",
            "|-------|----------|------------|-------|",
        ]
    )

    baseline_stats = baseline.skill_stats()
    hooks_stats = hooks.skill_stats()

    all_skills = set(baseline_stats.keys()) | set(hooks_stats.keys())
    for skill in sorted(all_skills):
        b_rate = baseline_stats.get(skill, {}).get("rate", 0) * 100
        h_rate = hooks_stats.get(skill, {}).get("rate", 0) * 100
        delta = h_rate - b_rate
        delta_str = f"+{delta:.0f}%" if delta >= 0 else f"{delta:.0f}%"
        lines.append(f"| {skill} | {b_rate:.0f}% | {h_rate:.0f}% | {delta_str} |")

    lines.extend(
        [
            "",
            "## Conclusion",
            "",
        ]
    )

    if improvement > 20:
        lines.append(
            "Forced skill hooks significantly improved activation rates."
        )
    elif improvement > 5:
        lines.append("Hooks provided moderate improvement in activation.")
    else:
        lines.append("Minimal difference between baseline and hooks-enabled runs.")

    lines.extend(
        [
            "",
            "---",
            "*Generated by claude-1337-evals*",
        ]
    )

    return "\n".join(lines)
