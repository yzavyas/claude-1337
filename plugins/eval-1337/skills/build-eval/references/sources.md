# Sources

Full citations for claims in SKILL.md.

---

## Anthropic (2026)

- [Demystifying Evals for AI Agents](https://www.anthropic.com/engineering/demystifying-evals-for-ai-agents) - Comprehensive agent evaluation guide (Jan 2026)
- [Bloom: Automated Behavioral Evaluations](https://alignment.anthropic.com/2025/bloom-auto-evals/) - Framework for behavioral evals
- [Statistical Approach to Model Evals](https://www.anthropic.com/research/statistical-approach-to-model-evals) - Clustering, paired differences
- [Building Effective Agents](https://www.anthropic.com/engineering/building-effective-agents) - Agent design and measurement

## Research

- [arxiv:2507.21504](https://arxiv.org/abs/2507.21504) - LLM Agent Evaluation Survey (KDD 2025)
- [MCPGauge](https://arxiv.org/abs/2506.07540) - MCP Server Evaluation (Jun 2025)
- [Scott Spence](https://scottspence.com/posts/how-to-make-claude-code-skills-activate-reliably) - Skills Activation Study (200+ tests)

## Frameworks

- [DeepEval](https://deepeval.com/docs/metrics-task-completion) - TaskCompletionMetric, ToolCorrectness
- [Braintrust](https://www.braintrust.dev/) - Offline evals + production observability
- [RAGAS](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/agents/) - Agent Metrics, ToolCallF1
- [Phoenix](https://docs.arize.com/phoenix) - LLM Observability and Tracing (local)
- [Promptfoo](https://promptfoo.dev/) - YAML-based assertions, red teaming
- [Harbor](https://github.com/ai-anchor/harbor) - Containerized task execution
- [LangSmith](https://smith.langchain.com/) - LangChain integration
- [Langfuse](https://langfuse.com/) - Self-hosted alternative

## Benchmarks

- [SWE-bench Verified](https://www.swebench.com/) - Code Agent Benchmark (500 verified)
- [Ï„2-Bench](https://github.com/tau-bench/tau-bench) - Multi-turn conversational (retail, airline)
- [WebArena](https://webarena.dev/) - Web agents (812 tasks)
- [OSWorld](https://os-world.github.io/) - Computer use agents

## Observability

- [OpenTelemetry GenAI](https://opentelemetry.io/blog/2025/ai-agent-observability/) - Semantic conventions for AI agents
- [Claude Agent SDK](https://code.claude.com/docs/en/monitoring-usage) - Native OTel
- [Google ADK](https://google.github.io/adk-docs/observability/cloud-trace/) - Native OTel

## Security

- [garak](https://github.com/leondz/garak) - LLM Vulnerability Scanner
- [OWASP LLM Top 10](https://owasp.org/www-project-top-10-for-large-language-model-applications/) - Security Risks
